堵住AI安全漏洞，法规之外更需技术制衡

	　　如今，AI换脸在网上被玩的不亦乐乎。喜欢哪个明星，就把所有电视剧主角都换成他的脸，如果只是单纯娱乐，貌似也无可厚非。但可怕的是，你的脸很可能会被到色情视频然后被打包贩卖，甚至你的手机、电脑、智能门锁等应用了人脸识别技术的设备也可能被AI换脸轻松攻破。有人用AI视频造假，亦或是犯罪，似乎就没那么好玩了。

	　　刷脸支付、人脸识别清华大学教授、清华大学人工智能研究院基础理论研究中心主任朱军说。

	　　北京瑞莱智慧科技有限公司（以下简称RealAI）高级产品经理张旭东在接受科技日报记者采访时说。

	　　技术漏洞带来AI安全问题

	　　回家，到单元楼门口，刷一下脸，门就开了。人脸解锁已经成为生活中最常见的AI应用场景之一。然而，很少有人会想到，当前的AI算法存在明显的。

	　　RealAI团队就曾做过相关研究：针对识别算法漏洞，可生成一类名为对抗样本的，只要戴上，即使不是本人，也能成功破解商用智能手机的刷脸解锁，甚至包括门锁等其他人脸识别设备。

	　　，或是检测出对抗样本以后将其从数据中去除，以及使用攻击算法生成大量对抗样本对模型做对抗训练等方式来解决这些问题。

	　　由于AI换脸技术也在不段进化，早期换脸技术生成的视频中人物往往不会眨眼，可根据一些较为明显的特征直接肉眼判断。但随着深度伪造技术的不断演化，这些鉴别方法已不再有效。

	　　张旭东说。

	　　要守好技术和法规两道关

	　　张旭东说。

	　　此外，AI技术滥用的潜在效应还将蔓延到大众的信息获取和社会信任层面，引导公众舆论、引发社会信任危机，比如美国就曾流出国家领导人被恶搞的视频，制作者利用视频煽动政治暴力、破坏选举、扰乱外交。长此以往，难以辨别真相的公众无法选择相信还是不相信，如果选择相信可能会继续给不法分子带来可趁之机，如果选择不相信则可能带来长期的社会冷漠。

	　　张旭东表示，AI安全问题牵一发而动全身，守好技术和法规两道是当务之急，同时需要联动社会各界力量，从监管机构、AI科技企业到普通公众共同重视、共同发力才能真正的从根本上使其良性发展。

	　　欣喜的是，AI安全问题已经引起国内相关监管机构的重视。此前，网信办就正式发布《网络音视频信息服务管理规定》，指出自2020年1月1日起，AI造假音视频不得随意发布。新规定中关于AI造假音视频的规定主要有四条：按照国家有关规定开展安全评估、以显著方式予以标识非真实音视频信息、不得利用AI造假技术发布虚假新闻、部署AI造假音视频鉴别技术和健全辟谣机制等。

	　　技术，从防御端铸造高墙，保障配备了人脸识别系统的公共安全设备攻不可破。（记者 付丽丽）

	　　
	
		　　 　　